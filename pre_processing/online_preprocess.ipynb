{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EEG preprocessing\n",
    "Meant for online processing of optimal C1 localization task\n",
    "should be as fast as possible to select online \n",
    "\n",
    "Written by Maximilien Van Migem \n",
    "\n",
    "Created on 24/01/2024 \n",
    "\"\"\"\n",
    "\n",
    "# Import some libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import glob\n",
    "import os\n",
    "%matplotlib qt \n",
    "\n",
    "# Import data file\n",
    "data_directory = 'C:/Users/mvmigem/Documents/data/project_1/localiser_dat/'\n",
    "dir_list = glob.glob(data_directory+'*')\n",
    "current_file_path = max(dir_list, key=os.path.getctime)\n",
    "print(current_file_path)\n",
    "\n",
    "raw = mne.io.read_raw_bdf(current_file_path, preload = True)\n",
    "\n",
    "# Rename and adress channels\n",
    "\n",
    "fix_chans = {'EXG1':'eye_above','EXG2':'eye_below',\n",
    "             'EXG3':'eye_left','EXG4':'eye_right',\n",
    "             'EXG5':'M1','EXG6':'M2'}\n",
    "raw.rename_channels(fix_chans)\n",
    "\n",
    "# we still have two exg channels which weren't actually recorded though (EXG7\n",
    "# and EXG8) these are empty, so we'll drop them\n",
    "raw.drop_channels(['EXG7', 'EXG8'])\n",
    "print(raw.info['ch_names'])\n",
    "\n",
    "# we'll also reset the channel types, so MNE knows what is 'brain' data\n",
    "raw.set_channel_types({'M1':'eeg', 'M2':'eeg',\n",
    "                       'eye_above':'eog', 'eye_below':'eog',\n",
    "                       'eye_left':'eog', 'eye_right': 'eog'})\n",
    "\n",
    "print(raw.info)\n",
    "\n",
    "# Rereference to mastoids\n",
    "raw.set_eeg_reference(ref_channels = ['M1','M2'])\n",
    "# then drop them\n",
    "raw.drop_channels(['M1','M2'])\n",
    "\n",
    "# Select montage\n",
    "montage = mne.channels.make_standard_montage('biosemi64')\n",
    "\n",
    "# There is a mismatch between the names of the recording and the names of the montage\n",
    "# This dict is to rename the channel names to fit the montage\n",
    "mon_chnames = montage.ch_names\n",
    "raw_chnames = raw.info['ch_names']\n",
    "rename_channels = dict(zip(raw_chnames[:64],mon_chnames))\n",
    "raw.rename_channels(rename_channels)\n",
    "\n",
    "# Set montage\n",
    "raw.set_montage(montage)\n",
    "\n",
    "# Downsampling variables (logic -> https://mne.tools/stable/auto_tutorials/preprocessing/30_filtering_resampling.html#best-practices)\n",
    "current_sfreq = raw.info['sfreq']\n",
    "desired_sfreq = 256  # Hz\n",
    "decim = np.round(current_sfreq / desired_sfreq).astype(int)\n",
    "obtained_sfreq = current_sfreq / decim\n",
    "lowpass_freq = obtained_sfreq / 3.\n",
    "\n",
    "\n",
    "raw_filtered = raw.copy().notch_filter(freqs = 50, fir_design = 'firwin', verbose=None,n_jobs=-1)\n",
    "raw_filtered = raw_filtered.copy().filter(l_freq=0.1, h_freq=lowpass_freq,n_jobs=-1)\n",
    "\n",
    "\n",
    "# Plot to reject bad channels manually\n",
    "raw_filtered.compute_psd().plot()\n",
    "raw_filtered.plot(n_channels=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then intepolate bad channels\n",
    "interp_filt_raw = raw_filtered.copy().interpolate_bads(reset_bads = True)\n",
    "\n",
    "# Annotate events\n",
    "events = mne.find_events(interp_filt_raw)\n",
    "# Event dict\n",
    "event_id = {        # This needs to be short in the online preprocess only 4 trigger markers (4 quads)\n",
    "    'position1':80,'position2':81, 'position3':82,'position4':83, \n",
    "}\n",
    "\n",
    "# Eye artifact rejection\n",
    "almost_clean = interp_filt_raw.copy()\n",
    "\n",
    "# we can also identify eog events algorithmically via \"find_eog_events\" this\n",
    "# produces a list of 'events' around each blink (hopefully). This applies a \n",
    "# filter and then identifies peaks in the eog to find likely blinks. We can \n",
    "# adjust the threshold, via thresh. but default should be okay for now.\n",
    "eog_events = mne.preprocessing.find_eog_events(almost_clean)\n",
    "# we'll say that the blinks start a tiny bit earlier than \n",
    "onsets = eog_events[:, 0] / almost_clean.info[\"sfreq\"] - 0.25\n",
    "# we'll assume they're all half a second long\n",
    "dur = [0.5] * len(eog_events)\n",
    "descriptions = [\"bad blink\"] * len(eog_events)\n",
    "blink_annot = mne.Annotations(onsets,\n",
    "                              dur,\n",
    "                              descriptions,\n",
    "                              orig_time = almost_clean.info[\"meas_date\"])\n",
    "almost_clean.set_annotations(blink_annot)\n",
    "\n",
    "# Epoch the data\n",
    "epochs_stimlock = mne.Epochs(almost_clean, events, event_id = event_id,\n",
    "    tmin = -0.1, tmax = 0.5, proj = False, baseline = (None,0), decim=decim, #from previous cell\n",
    "    detrend = None, verbose = True, reject_by_annotation= True, preload = True)\n",
    "\n",
    "# Evoked objects\n",
    "evoked_pos1 = epochs_stimlock['position1'].average()\n",
    "evoked_pos2 = epochs_stimlock['position2'].average()\n",
    "evoked_pos3 = epochs_stimlock['position3'].average()\n",
    "evoked_pos4 = epochs_stimlock['position4'].average()\n",
    "\n",
    "evokeds_list = [evoked_pos1,evoked_pos2,evoked_pos3,evoked_pos4]\n",
    "conds = ('position1','position2','position3','position4')\n",
    "evoked_pos = dict(zip(conds, evokeds_list))\n",
    "\n",
    "# Plot it all\n",
    "epoch_set1 = evoked_pos\n",
    "mne.viz.plot_compare_evokeds(epoch_set1, picks= 'Pz', vlines=[0.05,0.1],ylim=dict(eeg=[-10, 10]))\n",
    "mne.viz.plot_compare_evokeds(epoch_set1, picks= 'POz', vlines=[0.05,0.1],ylim=dict(eeg=[-10, 10]))\n",
    "mne.viz.plot_compare_evokeds(epoch_set1, picks= 'Oz', vlines=[0.05,0.1],ylim=dict(eeg=[-10, 10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_compare_evokeds(epoch_set1, picks= 'POz', vlines=[0.05,0.1],ylim=dict(eeg=[-6, 6]))\n",
    "mne.viz.plot_compare_evokeds(epoch_set1, picks= 'PO3', vlines=[0.05,0.1],ylim=dict(eeg=[-6, 6]))\n",
    "mne.viz.plot_compare_evokeds(epoch_set1, picks= 'PO4', vlines=[0.05,0.1],ylim=dict(eeg=[-6, 6]))\n",
    "mne.viz.plot_compare_evokeds(epoch_set1, picks= 'P1', vlines=[0.05,0.1],ylim=dict(eeg=[-6, 6]))\n",
    "mne.viz.plot_compare_evokeds(epoch_set1, picks= 'P2', vlines=[0.05,0.1],ylim=dict(eeg=[-6, 6]))\n",
    "mne.viz.plot_compare_evokeds(epoch_set1, picks= 'O1', vlines=[0.05,0.1],ylim=dict(eeg=[-6, 6]))\n",
    "mne.viz.plot_compare_evokeds(epoch_set1, picks= 'O2', vlines=[0.05,0.1],ylim=dict(eeg=[-6, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_compare_evokeds(epoch_set1, picks= 'Pz', vlines=[0.05,0.1],ylim=dict(eeg=[-10, 10]))\n",
    "mne.viz.plot_compare_evokeds(epoch_set1, picks= 'POz', vlines=[0.05,0.1],ylim=dict(eeg=[-10, 10]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
